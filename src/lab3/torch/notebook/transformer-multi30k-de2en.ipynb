{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a269ac2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-26T09:20:27.024878Z",
     "iopub.status.busy": "2025-04-26T09:20:27.024642Z",
     "iopub.status.idle": "2025-04-26T09:20:31.174535Z",
     "shell.execute_reply": "2025-04-26T09:20:31.173527Z"
    },
    "papermill": {
     "duration": 4.15667,
     "end_time": "2025-04-26T09:20:31.176050",
     "exception": false,
     "start_time": "2025-04-26T09:20:27.019380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\r\n",
      "Collecting download\r\n",
      "  Downloading download-0.3.5-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from download) (1.17.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from download) (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->download) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->download) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->download) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->download) (2025.1.31)\r\n",
      "Downloading download-0.3.5-py3-none-any.whl (8.8 kB)\r\n",
      "Installing collected packages: download\r\n",
      "Successfully installed download-0.3.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk tqdm download\n",
    "!mkdir ./log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c645659",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-26T09:20:31.184950Z",
     "iopub.status.busy": "2025-04-26T09:20:31.184705Z",
     "iopub.status.idle": "2025-04-26T09:20:36.651728Z",
     "shell.execute_reply": "2025-04-26T09:20:36.651112Z"
    },
    "papermill": {
     "duration": 5.472907,
     "end_time": "2025-04-26T09:20:36.653097",
     "exception": false,
     "start_time": "2025-04-26T09:20:31.180190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "from download import download\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.optim import AdamW\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4d0eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:20:36.661626Z",
     "iopub.status.busy": "2025-04-26T09:20:36.661324Z",
     "iopub.status.idle": "2025-04-26T09:20:36.728980Z",
     "shell.execute_reply": "2025-04-26T09:20:36.728289Z"
    },
    "papermill": {
     "duration": 0.072924,
     "end_time": "2025-04-26T09:20:36.730034",
     "exception": false,
     "start_time": "2025-04-26T09:20:36.657110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():  # 检查 Apple Silicon GPU 是否可用\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b486f",
   "metadata": {
    "papermill": {
     "duration": 0.003612,
     "end_time": "2025-04-26T09:20:36.737412",
     "exception": false,
     "start_time": "2025-04-26T09:20:36.733800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## # Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c27dc0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-26T09:20:36.745695Z",
     "iopub.status.busy": "2025-04-26T09:20:36.745472Z",
     "iopub.status.idle": "2025-04-26T09:20:36.757915Z",
     "shell.execute_reply": "2025-04-26T09:20:36.757211Z"
    },
    "papermill": {
     "duration": 0.017928,
     "end_time": "2025-04-26T09:20:36.758968",
     "exception": false,
     "start_time": "2025-04-26T09:20:36.741040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, special_tokens=None):\n",
    "        \"\"\"\n",
    "        :param special_tokens: 特殊标记列表，默认包含 '<PAD>': 0, '<UNK>':1, '<BOS>':2, '<EOS>':3\n",
    "        \"\"\"\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        if special_tokens is None:\n",
    "            special_tokens = [\"<PAD>\", \"<UNK>\", \"<BOS>\", \"<EOS>\"]\n",
    "        for token in special_tokens:\n",
    "            self.add_word(token)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        \"\"\"\n",
    "        向词表中添加单词\n",
    "        :param word: 要添加的单词\n",
    "        \"\"\"\n",
    "        if word not in self.word2idx:\n",
    "            idx = len(self.word2idx)\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "\n",
    "    def build_vocab(self, sentences, min_freq=1):\n",
    "        \"\"\"\n",
    "        基于句子列表构建词表，根据词频排序分配索引\n",
    "        :param sentences: 句子列表\n",
    "        :param min_freq: 最小词频限制\n",
    "        \"\"\"\n",
    "        # 统计词频\n",
    "        word_freq = Counter()\n",
    "        for sentence in sentences:\n",
    "            words = self.tokenize(sentence)  # 使用自定义的分词函数\n",
    "            for word in words:\n",
    "                word_freq[word] += 1\n",
    "\n",
    "        # 根据频率过滤词汇并排序\n",
    "        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 添加高频词到词表中\n",
    "        for word, _ in sorted_words:\n",
    "            if word_freq[word] >= min_freq:\n",
    "                self.add_word(word)\n",
    "\n",
    "    def encode(self, sentence, add_special_tokens=True, max_length=None):\n",
    "        \"\"\"\n",
    "        将句子转换为索引序列，并可选择性地添加<BOS>和<EOS>\n",
    "        :param sentence: 输入句子\n",
    "        :param add_special_tokens: 是否添加特殊标记\n",
    "        :param max_length: 句子的最大长度是多少，少了在末尾加入<PAD>，否则截断。\n",
    "        :return: 索引序列\n",
    "        \"\"\"\n",
    "        tokens = self.tokenize(sentence)\n",
    "        if add_special_tokens:\n",
    "            tokens = [\"<BOS>\"] + tokens + [\"<EOS>\"]\n",
    "\n",
    "        arr = [self.word2idx.get(word, self.word2idx[\"<UNK>\"]) for word in tokens]\n",
    "\n",
    "        if max_length is None:\n",
    "            return arr\n",
    "        else:\n",
    "            if len(arr) < max_length:\n",
    "                arr += [0] * (max_length - len(arr))\n",
    "                return arr\n",
    "            else:\n",
    "                return arr[: max_length - 1] + [3]\n",
    "\n",
    "    def decode(self, indices, ignore_special_tokens=False):\n",
    "        \"\"\"\n",
    "        将索引序列转换回句子，并可选择性地忽略特殊标记\n",
    "        :param indices: 索引序列\n",
    "        :param ignore_special_tokens: 是否忽略特殊标记\n",
    "        :return: 句子\n",
    "        \"\"\"\n",
    "        words = []\n",
    "        for idx in indices:\n",
    "            word = self.idx2word.get(idx, \"<UNK>\")\n",
    "            if ignore_special_tokens and word in [\"<PAD>\", \"<BOS>\", \"<EOS>\"]:\n",
    "                continue\n",
    "            words.append(word)\n",
    "        return words\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(file_path):\n",
    "        \"\"\"加载并返回文件中的所有句子\"\"\"\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            sentences = file.readlines()\n",
    "        return [sentence.strip() for sentence in sentences]\n",
    "\n",
    "    def save_vocab(self, path):\n",
    "        \"\"\"将词表保存到指定路径\"\"\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for word, idx in self.word2idx.items():\n",
    "                f.write(f\"{word}\\t{idx}\\n\")\n",
    "\n",
    "    def load_vocab(self, path):\n",
    "        \"\"\"从指定路径加载词表\"\"\"\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                word, idx = line.strip().split(\"\\t\")\n",
    "                idx = int(idx)\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word[idx] = word\n",
    "\n",
    "    def tokenize(self, sentence):\n",
    "        \"\"\"\n",
    "        分词函数，保留标点符号作为独立的标记\n",
    "        :param sentence: 输入句子\n",
    "        :return: 分词后的列表\n",
    "        \"\"\"\n",
    "        # 使用正则表达式分离单词和标点符号\n",
    "        words_and_punct = re.findall(r\"\\w+|[^\\w\\s]\", sentence, re.UNICODE)\n",
    "        return words_and_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5eabee",
   "metadata": {
    "papermill": {
     "duration": 0.00345,
     "end_time": "2025-04-26T09:20:36.766122",
     "exception": false,
     "start_time": "2025-04-26T09:20:36.762672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## # DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb49b8c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-26T09:20:36.774546Z",
     "iopub.status.busy": "2025-04-26T09:20:36.774332Z",
     "iopub.status.idle": "2025-04-26T09:20:42.037116Z",
     "shell.execute_reply": "2025-04-26T09:20:42.036266Z"
    },
    "papermill": {
     "duration": 5.268606,
     "end_time": "2025-04-26T09:20:42.038392",
     "exception": false,
     "start_time": "2025-04-26T09:20:36.769786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://modelscope.cn/api/v1/datasets/SelinaRR/Multi30K/repo?Revision=master&FilePath=Multi30K.zip (1 byte)\n",
      "\n",
      "file_sizes: 1.37MB [00:01, 1.13MB/s]\n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to ./\n",
      "Dataset downloaded and extracted.\n",
      "德文词表大小: 18487\n",
      "英文词表大小: 10829\n"
     ]
    }
   ],
   "source": [
    "# 定义自定义数据集类\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_sentences, trg_sentences, src_vocab, trg_vocab, max_length=50):\n",
    "        \"\"\"\n",
    "        初始化翻译数据集\n",
    "        :param src_sentences: 源语言句子列表\n",
    "        :param trg_sentences: 目标语言句子列表\n",
    "        :param src_vocab: 源语言词表 (Vocab 对象)\n",
    "        :param trg_vocab: 目标语言词表 (Vocab 对象)\n",
    "        :param max_length: 最大序列长度\n",
    "        \"\"\"\n",
    "        self.src_sentences = src_sentences\n",
    "        self.trg_sentences = trg_sentences\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence = self.src_sentences[idx]\n",
    "        trg_sentence = self.trg_sentences[idx]\n",
    "\n",
    "        # 编码源语言和目标语言句子\n",
    "        src_encoded = self.src_vocab.encode(src_sentence, add_special_tokens=True, max_length=self.max_length)\n",
    "        trg_encoded = self.trg_vocab.encode(trg_sentence, add_special_tokens=True, max_length=self.max_length)\n",
    "\n",
    "        return src_encoded, trg_encoded  # 返回元组 (src, trg)\n",
    "\n",
    "\n",
    "# 数据加载函数\n",
    "def load_datasets(\n",
    "    train_path, valid_path, test_path, src_vocab, trg_vocab, task, max_length=50, batch_size=32, drop_last=False\n",
    "):\n",
    "    \"\"\"\n",
    "    加载训练集、验证集和测试集\n",
    "    :param train_path: 训练集路径\n",
    "    :param valid_path: 验证集路径\n",
    "    :param test_path: 测试集路径\n",
    "    :param src_vocab: 源语言词表 (Vocab 对象)\n",
    "    :param trg_vocab: 目标语言词表 (Vocab 对象)\n",
    "    :param task: 任务，en->de or de->en\n",
    "    :param max_length: 最大序列长度\n",
    "    :param batch_size: 批量大小\n",
    "    :param drop_last: 是否丢弃最后一个不完整的批次\n",
    "    :return: 训练集、验证集和测试集的 DataLoader\n",
    "    \"\"\"\n",
    "    # 加载句子\n",
    "    train_src = Vocab.load_data(os.path.join(train_path, \"train.de\"))\n",
    "    train_trg = Vocab.load_data(os.path.join(train_path, \"train.en\"))\n",
    "\n",
    "    valid_src = Vocab.load_data(os.path.join(valid_path, \"val.de\"))\n",
    "    valid_trg = Vocab.load_data(os.path.join(valid_path, \"val.en\"))\n",
    "\n",
    "    test_src = Vocab.load_data(os.path.join(test_path, \"test2016.de\"))\n",
    "    test_trg = Vocab.load_data(os.path.join(test_path, \"test2016.en\"))\n",
    "\n",
    "    if task != 'de->en':\n",
    "        train_src, train_trg = train_trg, train_src\n",
    "        valid_src, valid_trg = valid_trg, valid_src\n",
    "        test_src, test_trg, test_trg, test_src\n",
    "\n",
    "    # 创建数据集\n",
    "    train_dataset = TranslationDataset(train_src, train_trg, src_vocab, trg_vocab, max_length=max_length)\n",
    "    valid_dataset = TranslationDataset(valid_src, valid_trg, src_vocab, trg_vocab, max_length=max_length)\n",
    "    test_dataset = TranslationDataset(test_src, test_trg, src_vocab, trg_vocab, max_length=max_length)\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda batch: list(zip(*batch)),\n",
    "        drop_last=drop_last,  # 控制是否丢弃最后一个批次\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda batch: list(zip(*batch)),\n",
    "        drop_last=drop_last,  # 控制是否丢弃最后一个批次\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda batch: list(zip(*batch)),\n",
    "        drop_last=drop_last,  # 控制是否丢弃最后一个批次\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "'''\n",
    "1. 数据集下载与解压\n",
    "2. 构建德文和英文的词表\n",
    "3. 构建DataLoader\n",
    "'''\n",
    "url = \"https://modelscope.cn/api/v1/datasets/SelinaRR/Multi30K/repo?Revision=master&FilePath=Multi30K.zip\"\n",
    "datasets_path = \"./datasets/\"\n",
    "train_path = os.path.join(datasets_path, \"train/\")\n",
    "valid_path = os.path.join(datasets_path, \"valid/\")\n",
    "test_path = os.path.join(datasets_path, \"test/\")\n",
    "\n",
    "if not os.path.exists(datasets_path):\n",
    "    download(url, \"./\", kind=\"zip\", replace=True)\n",
    "    print(\"Dataset downloaded and extracted.\")\n",
    "else:\n",
    "    print(\"Dataset is already downloaded.\")\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"task\": \"de->en\",\n",
    "    \"max_length\": 32,\n",
    "    \"batch_size\": 128\n",
    "}\n",
    "\n",
    "\n",
    "de_sentences = Vocab.load_data(os.path.join(train_path, \"train.de\"))\n",
    "en_sentences = Vocab.load_data(os.path.join(train_path, \"train.en\"))\n",
    "\n",
    "de_vocab = Vocab()\n",
    "de_vocab.build_vocab(de_sentences)\n",
    "\n",
    "en_vocab = Vocab()\n",
    "en_vocab.build_vocab(en_sentences)\n",
    "\n",
    "print(\"德文词表大小:\", len(de_vocab.word2idx))\n",
    "print(\"英文词表大小:\", len(en_vocab.word2idx))\n",
    "\n",
    "\n",
    "# 词表\n",
    "src_vocab, trg_vocab = (de_vocab, en_vocab) if config['task'] == 'de->en' else (en_vocab, de_vocab)\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader = load_datasets(\n",
    "    train_path=train_path,\n",
    "    valid_path=valid_path,\n",
    "    test_path=test_path,\n",
    "    src_vocab=src_vocab,\n",
    "    trg_vocab=trg_vocab,\n",
    "    task=config['task'],\n",
    "    max_length=config[\"max_length\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c154ec",
   "metadata": {
    "papermill": {
     "duration": 0.003984,
     "end_time": "2025-04-26T09:20:42.046881",
     "exception": false,
     "start_time": "2025-04-26T09:20:42.042897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## # Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5955672",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-26T09:20:42.056081Z",
     "iopub.status.busy": "2025-04-26T09:20:42.055872Z",
     "iopub.status.idle": "2025-04-26T09:20:42.085080Z",
     "shell.execute_reply": "2025-04-26T09:20:42.084589Z"
    },
    "papermill": {
     "duration": 0.035318,
     "end_time": "2025-04-26T09:20:42.086169",
     "exception": false,
     "start_time": "2025-04-26T09:20:42.050851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "B: batch_size\n",
    "L: max_len\n",
    "H: hidden size of K, Q, V after mapping from input\n",
    "D: embedding_size\n",
    "'''\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():  # 检查 Apple Silicon GPU 是否可用\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# 旋转位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, p=0., max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "\n",
    "        pe = torch.zeros(max_len, embedding_size)  # (L, D)\n",
    "\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # (L,) -> (L, 1)\n",
    "        div_term = torch.exp(torch.arange(0, embedding_size, 2, dtype=torch.float32) * (-torch.log(torch.tensor(10000.0)) / embedding_size))  # (D//2, )\n",
    "\n",
    "        # (L, 1) * (D/2, ) -> (L, D/2) * 2 -> (L, D//2)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # col列号, row是行号：pe[row] = sin(i / 10000^{col/D})\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # col奇数, row是行号：pe[row] = cos(i / 10000^{col-1/D})\n",
    "\n",
    "        pe = pe.unsqueeze(0)  # (L, D) -> (1, L, D)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: (B, L, D) -> x + pos\n",
    "        '''\n",
    "\n",
    "        _, seq_len, _ = x.size()\n",
    "\n",
    "        pos_encoding = self.pe[:, :seq_len, :]  # (1, L, D)\n",
    "        x = x + pos_encoding  # (B, L, D)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "# 自注意力机制\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, p=0.):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k: torch.Tensor, v, mask=None):\n",
    "        '''\n",
    "        q: (B, [N], Lq, D)\n",
    "        k: (B, [N], Lk, D)\n",
    "        v: (B, [N], Lk, D)\n",
    "        mask: (B, [N], Lq, Hk), fill: -inf\n",
    "\n",
    "        -> res: (B, [N], Lq, D), atten: (B, [N], Lk, Lk)\n",
    "        '''\n",
    "        embedding_size = q.size(dim=-1)\n",
    "        d = torch.sqrt(torch.tensor(embedding_size, dtype=torch.float16))\n",
    "\n",
    "        attention = torch.matmul(q, k.transpose(-1, -2) / d)  # (B, [N], Lq, D) @ (B, [N], D, Lk) / (1,) -> (B, [N], Lq, Lk)\n",
    "\n",
    "        if mask is not None:\n",
    "            attention = attention.masked_fill(mask, -torch.inf)  # mask: (B, 1, Lq, Lk) -> (B, [N], Lq, Lk), set True -> -inf\n",
    "\n",
    "        attention = self.softmax(attention)  # softmax on dim of Hk\n",
    "        attention = self.dropout(attention)\n",
    "\n",
    "        res = torch.matmul(attention, v)  # (B, [N], Lq, Lk) @ (B, [N], Lk, D) -> (B, [N], Lq, D), 这里就是对Lk所在的维度进行加权平均\n",
    "\n",
    "        return res, attention\n",
    "\n",
    "\n",
    "# 多头注意力\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_size, new_embedding_size, head_size, p=0.):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.n_head = head_size\n",
    "        self.new_embedding_size = new_embedding_size\n",
    "        self.linear_q = nn.Linear(embedding_size, self.new_embedding_size * self.n_head)\n",
    "        self.linear_k = nn.Linear(embedding_size, self.new_embedding_size * self.n_head)\n",
    "        self.linear_v = nn.Linear(embedding_size, self.new_embedding_size * self.n_head)\n",
    "        self.linear_o = nn.Linear(self.new_embedding_size * self.n_head, embedding_size)\n",
    "        self.attention = SelfAttention(p=p)\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k, v, mask: torch.Tensor):\n",
    "        '''\n",
    "        q: (B, Lq, D)\n",
    "        k: (B, Lk, D)\n",
    "        v: (B, Lk, D)\n",
    "        mask: (Lq, Lk), fill: -inf\n",
    "\n",
    "        -> res: (B, Lq, D), atten: (B, N, Lq, Lk)\n",
    "        '''\n",
    "        batch_size = q.size(dim=0)\n",
    "\n",
    "        Q = self.linear_q(q).view(batch_size, -1, self.n_head, self.new_embedding_size).transpose(1, 2)  # (B, Lq, N * D') -> (B, Lq, N, D') -> (B, N, Lq, D')\n",
    "        K = self.linear_k(k).view(batch_size, -1, self.n_head, self.new_embedding_size).transpose(1, 2)  # (B, Lk, N * D') -> (B, Lk, N, D') -> (B, N, Lk, D')\n",
    "        V = self.linear_v(v).view(batch_size, -1, self.n_head, self.new_embedding_size).transpose(1, 2)  # (B, Lk, N * D') -> (B, Lk, N, D') -> (B, N, Lk, D')\n",
    "\n",
    "        mask = mask.unsqueeze(1)  # (B, 1, Lq, Lk)\n",
    "        mask = mask.expand((-1, self.n_head, -1, -1))  # (B, N, Lq, Lk)\n",
    "\n",
    "        res, atten = self.attention(Q, K, V, mask)  # (B, N, Lq, D')\n",
    "\n",
    "        res = res.transpose(1, 2).reshape(batch_size, -1, self.new_embedding_size * self.n_head)  # (B, N, Lq, D') -> (B, Lq, N, D') -> (B, Lq, N * D')\n",
    "        res = self.linear_o(res)  # (B, Lq, N * D') -> (B, Lq, D)\n",
    "\n",
    "        return res, atten\n",
    "\n",
    "\n",
    "# 位置前馈神经网络\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size, p=0.):\n",
    "        super(FFN, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(embedding_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: (B, L, D)\n",
    "\n",
    "        -> (B, L, D)\n",
    "        '''\n",
    "\n",
    "        res = self.linear1(x)\n",
    "        res = self.relu(res)\n",
    "        res = self.dropout(res)\n",
    "        res = self.linear2(res)\n",
    "        return res\n",
    "\n",
    "\n",
    "# Add & Norm\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, embedding_size, p=0.):\n",
    "        super(AddNorm, self).__init__()\n",
    "\n",
    "        self.LN = nn.LayerNorm((embedding_size,))\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "\n",
    "    def forward(self, x, fx):\n",
    "        '''\n",
    "        x: (B, L, D)\n",
    "\n",
    "        -> (B, L, D)\n",
    "        '''\n",
    "\n",
    "        fx = self.dropout(fx)\n",
    "        return self.LN(x + fx)\n",
    "\n",
    "\n",
    "# Mask = <PAD> + SeeForward\n",
    "class Mask:\n",
    "    '''\n",
    "    where \"True\" is the place should be masked.\n",
    "\n",
    "    seq_q: (B, Lq), seq after vocab encode for q.\n",
    "    seq_k: (B, Lk), seq after vocab encode for k.\n",
    "\n",
    "    -> (B, Lq, Lk), mask\n",
    "    '''\n",
    "\n",
    "    def get_padding_mask(self, seq_q, seq_k, who_is_pad=0):\n",
    "        '''\n",
    "        <PAD> mask\n",
    "\n",
    "        seq_q: (B, Lq), seq after vocab encode for q.\n",
    "        seq_k: (B, Lk), seq after vocab encode for k.\n",
    "\n",
    "        -> (B, Lq, Lk), mask\n",
    "        '''\n",
    "\n",
    "        batch_size, Lq = seq_q.size()\n",
    "        batch_size, Lk = seq_k.size()\n",
    "\n",
    "        pad_mask = (seq_k == who_is_pad)  # (B, Lk)\n",
    "        pad_mask = pad_mask.unsqueeze(1).expand(batch_size, Lq, Lk)  # (B, Lk) -> (B, 1, Lk) -> (B, Lq, Lk)\n",
    "\n",
    "        return pad_mask\n",
    "\n",
    "    def get_causal_mask(self, seq_q, seq_k):\n",
    "        '''\n",
    "        causal mask\n",
    "\n",
    "        seq_q: (B, Lq), seq after vocab encode for q.\n",
    "        seq_k: (B, Lk), seq after vocab encode for k.\n",
    "\n",
    "        -> (B, Lq, Lk), mask\n",
    "        '''\n",
    "\n",
    "        B, Lq = seq_q.size()\n",
    "        _, Lk = seq_k.size()\n",
    "\n",
    "        mask = ~torch.tril(torch.ones(Lq, Lk)).bool()\n",
    "\n",
    "        mask = mask.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "'''\n",
    "Encoder\n",
    "'''\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, embedding_size, head_size, ffn_size, p=0.):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        new_embedding_size = embedding_size // head_size\n",
    "\n",
    "        if new_embedding_size * head_size != embedding_size:\n",
    "            raise ValueError(f'make sure embedding_size % head_size == 0, but get: {embedding_size} and {head_size}.')\n",
    "\n",
    "        self.encoder_self_attention = MultiHeadAttention(embedding_size, new_embedding_size, head_size, p)\n",
    "        self.ffn = FFN(ffn_size, embedding_size, p)\n",
    "\n",
    "        self.AN1 = AddNorm(embedding_size, p)\n",
    "        self.AN2 = AddNorm(embedding_size, p)\n",
    "\n",
    "    def forward(self, encoder_input, encoder_self_mask):\n",
    "        '''\n",
    "        encoder_input: (B, L) ~int ~raw_sentence\n",
    "        encoder_self_mask: (B, L, L) ~bool\n",
    "\n",
    "        -> (B, L, D) ~float\n",
    "        '''\n",
    "\n",
    "        # fx branch\n",
    "        x = encoder_input\n",
    "\n",
    "        fx, _ = self.encoder_self_attention(q=x, k=x, v=x, mask=encoder_self_mask)\n",
    "        out1 = self.AN1(x, fx)\n",
    "\n",
    "        x = out1\n",
    "\n",
    "        fx = self.ffn(x)\n",
    "        res = self.AN2(x, fx)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, embedding_size, head_size, ffn_size, num_blocks, p=0.):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.pos_embed = PositionalEncoding(embedding_size, p)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EncoderBlock(\n",
    "                embedding_size=embedding_size,\n",
    "                head_size=head_size,\n",
    "                ffn_size=ffn_size,\n",
    "                p=p\n",
    "            ) for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        self.scaling = torch.sqrt(torch.tensor(embedding_size))\n",
    "\n",
    "    def forward(self, encoder_input, src_who_is_pad):\n",
    "        '''\n",
    "        encoder_input: (B, L) ~int ~raw_sentence\n",
    "        src_who_is_pad: (,) ~int\n",
    "\n",
    "        -> (B, L, D) ~float\n",
    "        '''\n",
    "\n",
    "        embeded_encoder_input = self.embed(encoder_input)\n",
    "        embeded_encoder_input = self.pos_embed(embeded_encoder_input)\n",
    "\n",
    "        encoder_self_mask = Mask().get_padding_mask(seq_q=encoder_input,\n",
    "                                                    seq_k=encoder_input,\n",
    "                                                    who_is_pad=src_who_is_pad)\n",
    "\n",
    "        encoder_output = embeded_encoder_input\n",
    "        for block in self.blocks:\n",
    "            encoder_output = block(encoder_output, encoder_self_mask)\n",
    "\n",
    "        return encoder_output\n",
    "\n",
    "\n",
    "'''\n",
    "Decoder\n",
    "'''\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embedding_size, head_size, ffn_size, p=0.):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        one_head_embedding_size = embedding_size // head_size\n",
    "        if one_head_embedding_size * head_size != embedding_size:\n",
    "            raise ValueError(f'make sure embedding_size % head_size == 0, but get: {embedding_size} and {head_size}.')\n",
    "\n",
    "        self.decoder_self_attention = MultiHeadAttention(embedding_size, one_head_embedding_size, head_size, p)\n",
    "        self.decoder_encoder_attention = MultiHeadAttention(embedding_size, one_head_embedding_size, head_size, p)\n",
    "\n",
    "        self.ffn = FFN(ffn_size, embedding_size, p)\n",
    "\n",
    "        self.AN1 = AddNorm(embedding_size, p)\n",
    "        self.AN2 = AddNorm(embedding_size, p)\n",
    "        self.AN3 = AddNorm(embedding_size, p)\n",
    "\n",
    "    def forward(self, decoder_input, encoder_output, decoder_self_mask, decoder_encoder_mask):\n",
    "        '''\n",
    "        decoder_input: (B, L) ~int ~raw_sentence\n",
    "        encoder_output: (B, L, D) ~float\n",
    "        decoder_self_mask: (B, L, L) ~bool\n",
    "        decoder_encoder_mask: (B, L, L) ~bool\n",
    "\n",
    "        -> (B, L, D) ~float\n",
    "        '''\n",
    "\n",
    "        x = decoder_input\n",
    "\n",
    "        fx, _ = self.decoder_self_attention(q=x, k=x, v=x, mask=decoder_self_mask)\n",
    "        out1 = self.AN1(x, fx)\n",
    "\n",
    "        x = out1\n",
    "        fx, _ = self.decoder_encoder_attention(q=x, k=encoder_output, v=encoder_output, mask=decoder_encoder_mask)\n",
    "        out2 = self.AN2(x, fx)\n",
    "\n",
    "        x = out2\n",
    "\n",
    "        fx = self.ffn(x)\n",
    "        res = self.AN3(x, fx)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, trg_vocab_size, embedding_size, head_size, ffn_size, num_blocks, p=0.):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.pos_embed = PositionalEncoding(embedding_size, p)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DecoderBlock(\n",
    "                embedding_size=embedding_size,\n",
    "                head_size=head_size,\n",
    "                ffn_size=ffn_size,\n",
    "                p=p\n",
    "            ) for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        self.scaling = torch.sqrt(torch.tensor(embedding_size))\n",
    "        self.linear_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "\n",
    "    def forward(self, decoder_input, encoder_input, encoder_output, src_who_is_pad, trg_who_is_pad):\n",
    "        '''\n",
    "        decoder_input: (B, L) ~int ~raw_sentence\n",
    "        encoder_input: (B, L) ~int ~raw_sentence\n",
    "        encoder_output: (B, L, D) ~float\n",
    "        src_who_is_pad, trg_who_is_pad: (,) ~int\n",
    "\n",
    "        -> (B, L, trg_vocab_size) ~float\n",
    "        '''\n",
    "\n",
    "        embeded_decoder_input = self.embed(decoder_input)\n",
    "        embeded_decoder_input = self.pos_embed(embeded_decoder_input)\n",
    "\n",
    "        decoder_self_padding_mask = Mask().get_padding_mask(decoder_input, decoder_input, trg_who_is_pad)\n",
    "        decoder_self_causal_mask = Mask().get_causal_mask(decoder_input, decoder_input)\n",
    "        decoder_self_mask = decoder_self_padding_mask.to(device) | decoder_self_causal_mask.to(device)  # can not use 'or' here\n",
    "\n",
    "        decoder_encoder_padding_mask = Mask().get_padding_mask(decoder_input, encoder_input, src_who_is_pad)\n",
    "        decoder_encoder_mask = decoder_encoder_padding_mask\n",
    "\n",
    "        decoder_output = embeded_decoder_input\n",
    "        for block in self.blocks:\n",
    "            decoder_output = block(decoder_output, encoder_output, decoder_self_mask, decoder_encoder_mask)\n",
    "\n",
    "        decoder_output = self.linear_out(decoder_output)\n",
    "\n",
    "        return decoder_output\n",
    "\n",
    "\n",
    "'''\n",
    "Transformer\n",
    "'''\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, encoder_input, decoder_input, src_who_is_pad, trg_who_is_pad):\n",
    "        '''\n",
    "        encoder_input: (B, L) ~int ~raw_sentence\n",
    "        decoder_input: (B, L) ~int ~raw_sentence\n",
    "        src_who_is_pad, trg_who_is_pad: (,) ~int\n",
    "        '''\n",
    "        encoder_output = self.encoder(encoder_input, src_who_is_pad)\n",
    "\n",
    "        decoder_output = self.decoder(decoder_input, encoder_input, encoder_output, src_who_is_pad, trg_who_is_pad)\n",
    "\n",
    "        logits = decoder_output.view((-1, decoder_output.shape[-1]))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850c3c8",
   "metadata": {
    "papermill": {
     "duration": 0.003848,
     "end_time": "2025-04-26T09:20:42.094164",
     "exception": false,
     "start_time": "2025-04-26T09:20:42.090316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## # Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb1cd81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:20:42.103135Z",
     "iopub.status.busy": "2025-04-26T09:20:42.102920Z",
     "iopub.status.idle": "2025-04-26T09:20:42.117886Z",
     "shell.execute_reply": "2025-04-26T09:20:42.117390Z"
    },
    "papermill": {
     "duration": 0.020765,
     "end_time": "2025-04-26T09:20:42.118898",
     "exception": false,
     "start_time": "2025-04-26T09:20:42.098133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'log/training_{datetime.now().strftime(\"%Y%m%d_%H%M\")}.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class TransformerTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.model = Transformer(\n",
    "            encoder=Encoder(\n",
    "                src_vocab_size=len(src_vocab.word2idx),\n",
    "                embedding_size=config['d_model'],\n",
    "                head_size=config['n_head'],\n",
    "                ffn_size=config['ffn_size'],\n",
    "                num_blocks=config['num_blocks'],\n",
    "                p=config['dropout']\n",
    "            ),\n",
    "            decoder=Decoder(\n",
    "                trg_vocab_size=len(trg_vocab.word2idx),\n",
    "                embedding_size=config['d_model'],\n",
    "                head_size=config['n_head'],\n",
    "                ffn_size=config['ffn_size'],\n",
    "                num_blocks=config['num_blocks'],\n",
    "                p=config['dropout']\n",
    "            )\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.optimizer = AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=config['lr'],\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-9,\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "\n",
    "        self.lr_scheduler = LambdaLR(\n",
    "            self.optimizer,\n",
    "            lr_lambda=lambda step: min(\n",
    "                (step + 1) ** -0.5,\n",
    "                (step + 1) * (config['warmup_steps'] ** -1.5)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 混合精度训练\n",
    "        self.scaler = torch.amp.GradScaler(enabled=config['use_amp'])\n",
    "\n",
    "        # 损失函数（忽略padding）\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "        os.makedirs(config['output_dir'], exist_ok=True)\n",
    "\n",
    "    def _prepare_batch(self, batch):\n",
    "        \"\"\"处理原始批次数据\"\"\"\n",
    "        src_batch, trg_batch = batch\n",
    "        src_tensor = torch.tensor(src_batch).to(self.device)\n",
    "        trg_tensor = torch.tensor(trg_batch).to(self.device)\n",
    "\n",
    "        # 生成decoder输入输出\n",
    "        trg_input = trg_tensor[:, :-1]  # 移除最后一个token\n",
    "        trg_output = trg_tensor[:, 1:]  # 移除第一个token\n",
    "\n",
    "        # 生成mask\n",
    "        src_pad_mask = (src_tensor == 0).to(self.device)\n",
    "        trg_pad_mask = (trg_input == 0).to(self.device)\n",
    "\n",
    "        return {\n",
    "            'src': src_tensor,\n",
    "            'trg_input': trg_input,\n",
    "            'trg_output': trg_output,\n",
    "            'src_pad_mask': src_pad_mask,\n",
    "            'trg_pad_mask': trg_pad_mask\n",
    "        }\n",
    "\n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            prepared_batch = self._prepare_batch(batch)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=self.config['use_amp']):\n",
    "                logits = self.model(\n",
    "                    encoder_input=prepared_batch['src'],\n",
    "                    decoder_input=prepared_batch['trg_input'],\n",
    "                    src_who_is_pad=0,\n",
    "                    trg_who_is_pad=0\n",
    "                )\n",
    "\n",
    "                loss = self.criterion(\n",
    "                    logits.view(-1, len(trg_vocab.idx2word)),\n",
    "                    prepared_batch['trg_output'].contiguous().view(-1)\n",
    "                )\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.unscale_(self.optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.model.parameters(),\n",
    "                self.config['max_grad_norm']\n",
    "            )\n",
    "\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            self.lr_scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        return total_loss / len(train_loader)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, val_loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in val_loader:\n",
    "            prepared_batch = self._prepare_batch(batch)\n",
    "\n",
    "            logits = self.model(\n",
    "                encoder_input=prepared_batch['src'],\n",
    "                decoder_input=prepared_batch['trg_input'],\n",
    "                src_who_is_pad=0,\n",
    "                trg_who_is_pad=0\n",
    "            )\n",
    "\n",
    "            loss = self.criterion(\n",
    "                logits.view(-1, len(trg_vocab.idx2word)),\n",
    "                prepared_batch['trg_output'].contiguous().view(-1)\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(val_loader)\n",
    "\n",
    "    def save_checkpoint(self, epoch, is_best=False):\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state': self.model.state_dict(),\n",
    "            'optimizer_state': self.optimizer.state_dict(),\n",
    "            'scaler_state': self.scaler.state_dict(),\n",
    "            'config': self.config\n",
    "        }\n",
    "\n",
    "        filename = f\"checkpoint_epoch_{epoch}.pt\" if not is_best else \"best_model.pt\"\n",
    "        torch.save(state, os.path.join(self.config['output_dir'], filename))\n",
    "        logging.info(f\"Checkpoint saved: {filename}\")\n",
    "\n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        for epoch in range(1, self.config['num_epochs'] + 1):\n",
    "            logging.info(f\"Epoch {epoch}/{self.config['num_epochs']}\")\n",
    "            print(f\"Epoch {epoch}/{self.config['num_epochs']}\")\n",
    "\n",
    "            train_loss = self.train_epoch(train_loader)\n",
    "            logging.info(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "            if val_loader:\n",
    "                val_loss = self.validate(val_loader)\n",
    "                logging.info(f\"Val Loss: {val_loss:.4f}\")\n",
    "                print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    self.save_checkpoint(epoch, is_best=True)\n",
    "\n",
    "            if epoch % self.config['save_interval'] == 0:\n",
    "                self.save_checkpoint(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a2b1c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:20:42.127847Z",
     "iopub.status.busy": "2025-04-26T09:20:42.127201Z",
     "iopub.status.idle": "2025-04-26T09:40:31.295606Z",
     "shell.execute_reply": "2025-04-26T09:40:31.294756Z"
    },
    "papermill": {
     "duration": 1189.17426,
     "end_time": "2025-04-26T09:40:31.297057",
     "exception": false,
     "start_time": "2025-04-26T09:20:42.122797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/226 [00:00<?, ?it/s]/tmp/ipykernel_19/3928548719.py:100: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.config['use_amp']):\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8.0778\n",
      "Val Loss: 6.7698\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.2368\n",
      "Val Loss: 5.5060\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.1223\n",
      "Val Loss: 4.5634\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.3753\n",
      "Val Loss: 3.9801\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.9249\n",
      "Val Loss: 3.5942\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6047\n",
      "Val Loss: 3.3150\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.3390\n",
      "Val Loss: 3.0749\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.1117\n",
      "Val Loss: 2.8909\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.9123\n",
      "Val Loss: 2.7255\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.7363\n",
      "Val Loss: 2.5890\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.5833\n",
      "Val Loss: 2.4877\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.4444\n",
      "Val Loss: 2.3877\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.3160\n",
      "Val Loss: 2.2937\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1969\n",
      "Val Loss: 2.2342\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0871\n",
      "Val Loss: 2.1601\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9821\n",
      "Val Loss: 2.1062\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8810\n",
      "Val Loss: 2.0488\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7832\n",
      "Val Loss: 2.0077\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6854\n",
      "Val Loss: 1.9783\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5947\n",
      "Val Loss: 1.9475\n"
     ]
    }
   ],
   "source": [
    "# 加载训练配置\n",
    "config = {\n",
    "    \"d_model\": 512,\n",
    "    \"n_head\": 8,\n",
    "    \"ffn_size\": 2048,\n",
    "    \"num_blocks\": 6,\n",
    "    \"dropout\": 0.1,\n",
    "    \"num_epochs\": 20,\n",
    "    \"lr\": 0.005,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_steps\": 4000,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"output_dir\": \"./ckpts\",\n",
    "    \"save_interval\": 5,\n",
    "    \"use_amp\": True\n",
    "}\n",
    "\n",
    "# 初始化训练器\n",
    "trainer = TransformerTrainer(config)\n",
    "\n",
    "try:\n",
    "    trainer.train(train_loader, valid_loader)\n",
    "except KeyboardInterrupt:\n",
    "    logging.info(\"Training interrupted. Saving checkpoint...\")\n",
    "    trainer.save_checkpoint(epoch='interrupted')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Training failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624a3b9",
   "metadata": {
    "papermill": {
     "duration": 0.37777,
     "end_time": "2025-04-26T09:40:32.098819",
     "exception": false,
     "start_time": "2025-04-26T09:40:31.721049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## # Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3fd4fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:40:32.889166Z",
     "iopub.status.busy": "2025-04-26T09:40:32.888791Z",
     "iopub.status.idle": "2025-04-26T09:40:32.899897Z",
     "shell.execute_reply": "2025-04-26T09:40:32.899370Z"
    },
    "papermill": {
     "duration": 0.434485,
     "end_time": "2025-04-26T09:40:32.900944",
     "exception": false,
     "start_time": "2025-04-26T09:40:32.466459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    def __init__(self, model_path, src_vocab, trg_vocab):\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():  # 检查 Apple Silicon GPU 是否可用\n",
    "            device = torch.device(\"mps\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "\n",
    "        # 加载模型\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        self.config = checkpoint['config']\n",
    "\n",
    "        self.model = Transformer(\n",
    "            encoder=Encoder(\n",
    "                src_vocab_size=len(src_vocab.word2idx),\n",
    "                embedding_size=self.config['d_model'],\n",
    "                head_size=self.config['n_head'],\n",
    "                ffn_size=self.config['ffn_size'],\n",
    "                num_blocks=self.config['num_blocks'],\n",
    "                p=0.0  # 推理时关闭dropout\n",
    "            ),\n",
    "            decoder=Decoder(\n",
    "                trg_vocab_size=len(trg_vocab.word2idx),\n",
    "                embedding_size=self.config['d_model'],\n",
    "                head_size=self.config['n_head'],\n",
    "                ffn_size=self.config['ffn_size'],\n",
    "                num_blocks=self.config['num_blocks'],\n",
    "                p=0.0\n",
    "            )\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.model.load_state_dict(checkpoint['model_state'])\n",
    "        self.model.eval()\n",
    "\n",
    "    def _prepare_input(self, src_seq):\n",
    "        \"\"\"处理输入序列\"\"\"\n",
    "        src_tensor = torch.tensor([2] + src_seq + [3]).to(self.device)\n",
    "\n",
    "        # 添加batch维度并填充\n",
    "        src_tensor = src_tensor.unsqueeze(0)  # [1, seq_len]\n",
    "        src_pad_mask = (src_tensor == 0)\n",
    "        return src_tensor, src_pad_mask\n",
    "\n",
    "    def translate(self, src_seq, max_length=50):\n",
    "        \"\"\"使用贪心算法进行翻译\"\"\"\n",
    "        src_tensor, src_pad_mask = self._prepare_input(src_seq)\n",
    "\n",
    "        # 初始化decoder输入\n",
    "        decoder_input = torch.tensor([[2]]).to(self.device)\n",
    "\n",
    "        # 自回归生成\n",
    "        for _ in range(max_length):\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(\n",
    "                    encoder_input=src_tensor,\n",
    "                    decoder_input=decoder_input,\n",
    "                    src_who_is_pad=0,\n",
    "                    trg_who_is_pad=0\n",
    "                )\n",
    "\n",
    "            # 获取最后一个token的预测\n",
    "            # print(logits)\n",
    "            next_token = logits[-1, :].argmax(-1)\n",
    "            # print(next_token)\n",
    "            # print()\n",
    "            # print(f'decoder input: {decoder_input}')\n",
    "            decoder_input = torch.cat(\n",
    "                [decoder_input, next_token.unsqueeze(0).unsqueeze(0)], dim=-1\n",
    "            )\n",
    "\n",
    "            # 遇到EOS则停止，同时拼接EOS\n",
    "            if next_token.item() == 3:\n",
    "                decoder_input = torch.cat(\n",
    "                    [decoder_input, torch.tensor(3).unsqueeze(0).unsqueeze(0).to(self.device)], dim=-1\n",
    "                )\n",
    "                break\n",
    "\n",
    "        # 转换为token列表\n",
    "        output_tokens = decoder_input[0].cpu().tolist()\n",
    "\n",
    "        # 去除特殊token并解码\n",
    "        filtered = [\n",
    "            t for t in output_tokens\n",
    "            if t not in {2, 3, 0}\n",
    "        ]\n",
    "\n",
    "        return self.trg_vocab.decode(filtered)\n",
    "\n",
    "    def calculate_bleu(self, test_loader_):\n",
    "        \"\"\"计算整个测试集的BLEU分数\"\"\"\n",
    "        references = []\n",
    "        hypotheses = []\n",
    "\n",
    "        for batch in tqdm(test_loader_, desc=\"Calculating BLEU\"):\n",
    "            src_batch, trg_batch = batch\n",
    "\n",
    "            # 处理每个样本\n",
    "            for src_seq, trg_seq in zip(src_batch, trg_batch):\n",
    "                # 解码参考翻译\n",
    "                ref = [self.trg_vocab.decode([t for t in trg_seq if t not in {0}])]\n",
    "\n",
    "                # 生成模型翻译\n",
    "                hyp = self.translate(src_seq)\n",
    "\n",
    "                references.append(ref)\n",
    "                hypotheses.append(hyp)\n",
    "\n",
    "        # 计算corpus BLEU\n",
    "        return corpus_bleu(references, hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a14baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:40:33.621000Z",
     "iopub.status.busy": "2025-04-26T09:40:33.620177Z",
     "iopub.status.idle": "2025-04-26T09:40:34.945225Z",
     "shell.execute_reply": "2025-04-26T09:40:34.944231Z"
    },
    "papermill": {
     "duration": 1.684953,
     "end_time": "2025-04-26T09:40:34.946985",
     "exception": false,
     "start_time": "2025-04-26T09:40:33.262032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/500338390.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.device)\n"
     ]
    }
   ],
   "source": [
    "# 初始化翻译器\n",
    "translator = Translator(\n",
    "    model_path='ckpts/best_model.pt',\n",
    "    src_vocab=src_vocab,\n",
    "    trg_vocab=trg_vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777d587",
   "metadata": {
    "papermill": {
     "duration": 0.348531,
     "end_time": "2025-04-26T09:40:35.698328",
     "exception": false,
     "start_time": "2025-04-26T09:40:35.349797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### # 1. Some Examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96be451c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:40:36.451371Z",
     "iopub.status.busy": "2025-04-26T09:40:36.451085Z",
     "iopub.status.idle": "2025-04-26T09:40:37.596502Z",
     "shell.execute_reply": "2025-04-26T09:40:37.595842Z"
    },
    "papermill": {
     "duration": 1.549236,
     "end_time": "2025-04-26T09:40:37.597868",
     "exception": false,
     "start_time": "2025-04-26T09:40:36.048632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Translations (German -> English):\n",
      "\n",
      "Source (German)                : Die Katze ist auf dem Tisch .\n",
      "Reference Translation (English): The cat is on the table.\n",
      "Model Translation (English)    : The cat is on the table .\n",
      "\n",
      "Source (German)                : Sie liest jeden Tag ein Buch .\n",
      "Reference Translation (English): She reads a book every day.\n",
      "Model Translation (English)    : They are reading a book on the day .\n",
      "\n",
      "Source (German)                : Der Hund spielt im Garten .\n",
      "Reference Translation (English): The dog is playing in the garden.\n",
      "Model Translation (English)    : The dog is playing in the garden .\n",
      "\n",
      "Source (German)                : Wir gehen ins Kino heute Abend .\n",
      "Reference Translation (English): We are going to the cinema this evening.\n",
      "Model Translation (English)    : We are walking in the air at the ocean .\n",
      "\n",
      "Source (German)                : Das Wetter ist sehr schön heute .\n",
      "Reference Translation (English): The weather is very nice today.\n",
      "Model Translation (English)    : The very happy is very happy .\n",
      "\n",
      "Source (German)                : Er hat eine rote Jacke an .\n",
      "Reference Translation (English): He is wearing a red jacket.\n",
      "Model Translation (English)    : He has a red jacket on his jacket .\n",
      "\n",
      "Source (German)                : Ich habe Hunger .\n",
      "Reference Translation (English): I am hungry.\n",
      "Model Translation (English)    : The two men are having a game of water .\n",
      "\n",
      "Source (German)                : Es gibt viele Bücher im Regal .\n",
      "Reference Translation (English): There are many books on the shelf.\n",
      "Model Translation (English)    : There is many people gathered in the air .\n",
      "\n",
      "Source (German)                : Kannst du mir helfen, bitte ?\n",
      "Reference Translation (English): Can you help me, please?\n",
      "Model Translation (English)    : The performer is digging to be seen from the street corner .\n",
      "\n",
      "Source (German)                : Morgen werde ich einkaufen gehen .\n",
      "Reference Translation (English): Tomorrow I will go shopping.\n",
      "Model Translation (English)    : The hockey game is walking in the mountains .\n"
     ]
    }
   ],
   "source": [
    "# 示例翻译 - 德语到英语，包含标准答案\n",
    "example_src_with_refs = [\n",
    "    (\"Die Katze ist auf dem Tisch .\", \"The cat is on the table.\"),\n",
    "    (\"Sie liest jeden Tag ein Buch .\", \"She reads a book every day.\"),\n",
    "    (\"Der Hund spielt im Garten .\", \"The dog is playing in the garden.\"),\n",
    "    (\"Wir gehen ins Kino heute Abend .\", \"We are going to the cinema this evening.\"),\n",
    "    (\"Das Wetter ist sehr schön heute .\", \"The weather is very nice today.\"),\n",
    "    (\"Er hat eine rote Jacke an .\", \"He is wearing a red jacket.\"),\n",
    "    (\"Ich habe Hunger .\", \"I am hungry.\"),\n",
    "    (\"Es gibt viele Bücher im Regal .\", \"There are many books on the shelf.\"),\n",
    "    (\"Kannst du mir helfen, bitte ?\", \"Can you help me, please?\"),\n",
    "    (\"Morgen werde ich einkaufen gehen .\", \"Tomorrow I will go shopping.\")\n",
    "]\n",
    "\n",
    "print(\"\\nExample Translations (German -> English):\")\n",
    "for src, ref_translation in example_src_with_refs:\n",
    "    # 编码源句子\n",
    "    src_encoded = src_vocab.encode(src, add_special_tokens=False)\n",
    "\n",
    "    # 生成翻译\n",
    "    translation = translator.translate(src_encoded)\n",
    "    translation = \" \".join(translation)\n",
    "\n",
    "    # 打印双语对照结果，包括标准答案\n",
    "    print()\n",
    "    print(f\"Source (German)                : {src}\")\n",
    "    print(f\"Reference Translation (English): {ref_translation}\")\n",
    "    print(f\"Model Translation (English)    : {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3ca50b",
   "metadata": {
    "papermill": {
     "duration": 0.421641,
     "end_time": "2025-04-26T09:40:38.373062",
     "exception": false,
     "start_time": "2025-04-26T09:40:37.951421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### # 2. BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd2666eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T09:40:39.077809Z",
     "iopub.status.busy": "2025-04-26T09:40:39.077561Z",
     "iopub.status.idle": "2025-04-26T09:42:59.153946Z",
     "shell.execute_reply": "2025-04-26T09:42:59.153093Z"
    },
    "papermill": {
     "duration": 140.425131,
     "end_time": "2025-04-26T09:42:59.155040",
     "exception": false,
     "start_time": "2025-04-26T09:40:38.729909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating BLEU: 100%|██████████| 7/7 [02:20<00:00, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLEU Score: 0.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 计算 BLEU 分数\n",
    "if True:\n",
    "    bleu_score = translator.calculate_bleu(test_loader)\n",
    "    print(f\"\\nBLEU Score: {bleu_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1358.991914,
   "end_time": "2025-04-26T09:43:01.928032",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-26T09:20:22.936118",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
