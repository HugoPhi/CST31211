{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9052f2a5-27d7-4d8e-a90d-d082d9f6fd47",
   "metadata": {},
   "source": [
    "# # De2En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a71ea26-bea9-4495-a259-d34b844c7542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already downloaded!\n"
     ]
    }
   ],
   "source": [
    "from download import download\n",
    "import re\n",
    "\n",
    "url = \"https://modelscope.cn/api/v1/datasets/SelinaRR/Multi30K/repo?Revision=master&FilePath=Multi30K.zip\"\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./datasets'):\n",
    "    download(url, './', kind='zip', replace=True)\n",
    "else:\n",
    "    print('already downloaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8929137d-68ac-4b44-b6cc-9e68d53eee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================datasets in ./datasets/train/train.de========================================\n",
      "0 Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
      "1 Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n",
      "2 Ein kleines Mädchen klettert in ein Spielhaus aus Holz.\n",
      "3 Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.\n",
      "4 Zwei Männer stehen am Herd und bereiten Essen zu.\n",
      "========================================datasets in ./datasets/train/train.en========================================\n",
      "0 Two young, White males are outside near many bushes.\n",
      "1 Several men in hard hats are operating a giant pulley system.\n",
      "2 A little girl climbing into a wooden playhouse.\n",
      "3 A man in a blue shirt is standing on a ladder cleaning a window.\n",
      "4 Two men are at the stove preparing food.\n"
     ]
    }
   ],
   "source": [
    "datasets_path = './datasets/'\n",
    "train_path = datasets_path + 'train/'\n",
    "valid_path = datasets_path + 'valid/'\n",
    "test_path = datasets_path + 'test/'\n",
    "\n",
    "def print_data(data_file_path, print_n=5):\n",
    "    print(\"=\" * 40 + \"datasets in {}\".format(data_file_path) + \"=\" * 40)\n",
    "    with open(data_file_path, 'r', encoding='utf-8') as en_file:\n",
    "        en = en_file.readlines()[:print_n]\n",
    "        for index, seq in enumerate(en):\n",
    "            print(index, seq.replace('\\n', ''))\n",
    "\n",
    "\n",
    "print_data(train_path + 'train.de')\n",
    "print_data(train_path + 'train.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f0f87a-ab35-4810-a6ac-13d3ec3b68ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "德文：['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']\n",
      "英文：['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class Multi30K():\n",
    "    \"\"\"Multi30K数据集加载器，加载Multi30K数据集并处理为一个Python迭代对象\"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.data = self._load(path)\n",
    "\n",
    "    def _load(self, path):\n",
    "        def tokenize(text):\n",
    "            text = text.rstrip()\n",
    "            return [tok.lower() for tok in re.findall(r'\\w+|[^\\w\\s]', text)]\n",
    "        \n",
    "        def read_data(data_file_path):\n",
    "            with open(data_file_path, 'r', encoding='utf-8') as data_file:\n",
    "                data = data_file.readlines()[:-1]\n",
    "                return [tokenize(i) for i in data]\n",
    "\n",
    "        members = {i.split('.')[-1]: path + i for i in os.listdir(path)}\n",
    "        ret = [read_data(members['de']), read_data(members['en'])]\n",
    "        return list(zip(*ret))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = Multi30K(train_path), Multi30K(valid_path), Multi30K(test_path)\n",
    "\n",
    "for de, en in train_dataset:\n",
    "    print(f'德文：{de}')\n",
    "    print(f'英文：{en}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cfa794-fc08-4790-b910-7129bb844a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"通过词频字典，构建词典\"\"\"\n",
    "\n",
    "    special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "    def __init__(self, word_count_dict, min_freq=1):\n",
    "        self.word2idx = {}\n",
    "        for idx, tok in enumerate(self.special_tokens):\n",
    "            self.word2idx[tok] = idx\n",
    "\n",
    "        filted_dict = {w: c for w, c in word_count_dict.items() if c >= min_freq}\n",
    "        for w, _ in filted_dict.items():\n",
    "            self.word2idx[w] = len(self.word2idx)\n",
    "\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "\n",
    "        self.bos_idx = self.word2idx['<bos>']\n",
    "        self.eos_idx = self.word2idx['<eos>']\n",
    "        self.pad_idx = self.word2idx['<pad>']\n",
    "        self.unk_idx = self.word2idx['<unk>']\n",
    "\n",
    "    def _word2idx(self, word):\n",
    "        \"\"\"单词映射至数字索引\"\"\"\n",
    "        if word not in self.word2idx:\n",
    "            return self.unk_idx\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def _idx2word(self, idx):\n",
    "        \"\"\"数字索引映射至单词\"\"\"\n",
    "        if idx not in self.idx2word:\n",
    "            raise ValueError('input index is not in vocabulary.')\n",
    "        return self.idx2word[idx]\n",
    "\n",
    "    def encode(self, word_or_list):\n",
    "        \"\"\"将单个单词或单词数组映射至单个数字索引或数字索引数组\"\"\"\n",
    "        if isinstance(word_or_list, list):\n",
    "            return [self._word2idx(i) for i in word_or_list]\n",
    "        return self._word2idx(word_or_list)\n",
    "\n",
    "    def decode(self, idx_or_list):\n",
    "        \"\"\"将单个数字索引或数字索引数组映射至单个单词或单词数组\"\"\"\n",
    "        if isinstance(idx_or_list, list):\n",
    "            return [self._idx2word(i) for i in idx_or_list]\n",
    "        return self._idx2word(idx_or_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e143668c-3142-48dd-bb89-65e079320dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in de vocabulary:7882 and en vocabulary:5898\n",
      "\n",
      "word:['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n",
      "index:[16, 24, 15, 25, 776, 17, 57, 80, 204, 1305, 5]\n",
      "\n",
      "index:[5, 6, 7, 8, 9, 10]\n",
      "word:['.', 'in', 'the', 'on', 'man', 'is']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "def build_vocab(dataset):\n",
    "    de_words, en_words = [], []\n",
    "    for de, en in dataset:\n",
    "        de_words.extend(de)\n",
    "        en_words.extend(en)\n",
    "    \n",
    "    de_count_dict = OrderedDict(sorted(Counter(de_words).items(), key=lambda t: t[1], reverse=True))\n",
    "    en_count_dict = OrderedDict(sorted(Counter(en_words).items(), key=lambda t: t[1], reverse=True))\n",
    "\n",
    "    return Vocab(de_count_dict, min_freq=2), Vocab(en_count_dict, min_freq=2)\n",
    "\n",
    "de_vocab, en_vocab = build_vocab(train_dataset)\n",
    "print('Unique tokens in de vocabulary:{} and en vocabulary:{}\\n'.format(len(de_vocab), len(en_vocab)))\n",
    "\n",
    "str_seq_en = ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n",
    "print(\"word:{}\\nindex:{}\\n\".format(str_seq_en, en_vocab.encode(str_seq_en)))\n",
    "\n",
    "index = [5, 6, 7, 8, 9, 10]\n",
    "print(\"index:{}\\nword:{}\".format(index, en_vocab.decode(index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "960f33b4-9283-4a6d-b375-1e2691f466ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:23:27.276.855 [mindspore/run_check/_check_version.py:357] MindSpore version 2.2.13 and Ascend AI software package (Ascend Data Center Solution)version 7.0 does not match, the version of software package expect one of ['7.1']. Please refer to the match info on: https://www.mindspore.cn/install\n",
      "/usr/local/Ascend/ascend-toolkit/7.0.RC1/python/site-packages/tbe/tvm/contrib/ccec.py:766: DeprecationWarning: invalid escape sequence \\L\n",
      "  if not dirpath.find(\"AppData\\Local\\Temp\"):\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/classifier/transdata/transdata_classifier.py:222: DeprecationWarning: invalid escape sequence \\B\n",
      "  \"\"\"\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/vector/transdata/common/graph/transdata_graph_info.py:140: DeprecationWarning: invalid escape sequence \\c\n",
      "  \"\"\"\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:23:34.129.755 [mindspore/run_check/_check_version.py:375] MindSpore version 2.2.13 and \"te\" wheel package version 7.0 does not match. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:23:34.132.340 [mindspore/run_check/_check_version.py:382] MindSpore version 2.2.13 and \"hccl\" wheel package version 7.0 does not match. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:23:34.133.080 [mindspore/run_check/_check_version.py:396] Please pay attention to the above warning, countdown: 3\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:23:35.134.938 [mindspore/run_check/_check_version.py:396] Please pay attention to the above warning, countdown: 2\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:23:36.136.893 [mindspore/run_check/_check_version.py:396] Please pay attention to the above warning, countdown: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_idx.shape:(128, 32)\n",
      "[[ 2  5 13 ...  1  1  1]\n",
      " [ 2  5 13 ...  1  1  1]\n",
      " [ 2  5 13 ...  1  1  1]\n",
      " ...\n",
      " [ 2  5 52 ...  1  1  1]\n",
      " [ 2  8 37 ...  1  1  1]\n",
      " [ 2  5 33 ...  1  1  1]]\n",
      "src_len.shape:(128,)\n",
      "[27 25 24 24 23 23 23 23 22 22 22 21 21 21 21 21 20 20 20 20 20 19 19 19\n",
      " 18 18 18 18 18 18 18 18 17 17 17 17 17 17 17 17 17 17 16 16 16 16 16 16\n",
      " 16 16 16 16 15 15 15 15 15 15 15 15 15 15 15 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 13 13 13 13 13 13 13 13 13 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 11 11 11 11 11 11 11 11 11 11 10 10 10 10 10 10\n",
      " 10  9  9  9  9  9  9  8]\n",
      "trg_idx.shape:(128, 32)\n",
      "[[   2    4 2243 ...    1    1    1]\n",
      " [   2    4    9 ...    1    1    1]\n",
      " [   2    4    9 ...    1    1    1]\n",
      " ...\n",
      " [   2    4   55 ...    1    1    1]\n",
      " [   2    4   38 ...    1    1    1]\n",
      " [   2    4   35 ...    1    1    1]]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "\n",
    "class Iterator():\n",
    "    \"\"\"创建数据迭代器\"\"\"\n",
    "    def __init__(self, dataset, de_vocab, en_vocab, batch_size, max_len=32, drop_reminder=False):\n",
    "        self.dataset = dataset\n",
    "        self.de_vocab = de_vocab\n",
    "        self.en_vocab = en_vocab\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.drop_reminder = drop_reminder\n",
    "\n",
    "        length = len(self.dataset) // batch_size\n",
    "        self.len = length if drop_reminder else length + 1  # 批量数量\n",
    "\n",
    "    def __call__(self):\n",
    "        def pad(idx_list, vocab, max_len):\n",
    "            \"\"\"统一序列长度，并记录有效长度\"\"\"\n",
    "            idx_pad_list, idx_len = [], []\n",
    "            for i in idx_list:\n",
    "                if len(i) > max_len - 2:\n",
    "                    idx_pad_list.append([vocab.bos_idx] + i[:max_len-2] + [vocab.eos_idx])\n",
    "                    idx_len.append(max_len)\n",
    "                else:\n",
    "                    idx_pad_list.append([vocab.bos_idx] + i + [vocab.eos_idx] + [vocab.pad_idx] * (max_len - len(i) - 2))\n",
    "                    idx_len.append(len(i) + 2)\n",
    "            return idx_pad_list, idx_len\n",
    "\n",
    "        def sort_by_length(src, trg):\n",
    "            \"\"\"根据src的字段长度进行排序\"\"\"\n",
    "            data = zip(src, trg)\n",
    "            data = sorted(data, key=lambda t: len(t[0]), reverse=True)\n",
    "            return zip(*list(data))\n",
    "\n",
    "        def encode_and_pad(batch_data, max_len):\n",
    "            \"\"\"将批量中的文本数据转换为数字索引，并统一每个序列的长度\"\"\"\n",
    "            src_data, trg_data = zip(*batch_data)\n",
    "            src_idx = [self.de_vocab.encode(i) for i in src_data]\n",
    "            trg_idx = [self.en_vocab.encode(i) for i in trg_data]\n",
    "\n",
    "            src_idx, trg_idx = sort_by_length(src_idx, trg_idx)\n",
    "            src_idx_pad, src_len = pad(src_idx, de_vocab, max_len)\n",
    "            trg_idx_pad, _ = pad(trg_idx, en_vocab, max_len)\n",
    "\n",
    "            return src_idx_pad, src_len, trg_idx_pad\n",
    "\n",
    "        for i in range(self.len):\n",
    "            if i == self.len - 1 and not self.drop_reminder:\n",
    "                batch_data = self.dataset[i * self.batch_size:]\n",
    "            else:\n",
    "                batch_data = self.dataset[i * self.batch_size: (i+1) * self.batch_size]\n",
    "\n",
    "            src_idx, src_len, trg_idx = encode_and_pad(batch_data, self.max_len)\n",
    "            yield mindspore.Tensor(src_idx, mindspore.int32), \\\n",
    "                mindspore.Tensor(src_len, mindspore.int32), \\\n",
    "                mindspore.Tensor(trg_idx, mindspore.int32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "train_iterator = Iterator(train_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=True)\n",
    "valid_iterator = Iterator(valid_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=False)\n",
    "test_iterator = Iterator(test_dataset, de_vocab, en_vocab, batch_size=1, max_len=32, drop_reminder=False)\n",
    "\n",
    "for src_idx, src_len, trg_idx in train_iterator():\n",
    "    print(f'src_idx.shape:{src_idx.shape}\\n{src_idx}\\nsrc_len.shape:{src_len.shape}\\n{src_len}\\ntrg_idx.shape:{trg_idx.shape}\\n{trg_idx}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa780b94-b8ab-4b15-bf43-42b6dfb2516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00570505 -0.02154015  0.00194228  0.00260896]\n",
      " [ 0.00827621 -0.00191404 -0.00111004  0.01725669]\n",
      " [ 0.00684263 -0.0083806  -0.00410524  0.01039678]\n",
      " [ 0.00318643  0.01291807 -0.0111532   0.00159756]\n",
      " [ 0.00309748  0.00189072  0.00322005 -0.00049134]\n",
      " [ 0.01441898 -0.00799991 -0.00842194  0.00682251]\n",
      " [ 0.00684263 -0.0083806  -0.00410524  0.01039678]\n",
      " [-0.01625689  0.00231538  0.01427712 -0.01079916]\n",
      " [ 0.00346014 -0.00493062  0.00570861  0.01259992]\n",
      " [ 0.00585919  0.01821006  0.0053578   0.01021233]]\n"
     ]
    }
   ],
   "source": [
    "from mindspore import nn, Tensor\n",
    "\n",
    "word_index = Tensor([21, 28, 49, 12, 275, 119, 49, 23, 54, 32])\n",
    "src_emb = nn.Embedding(len(de_vocab), 4)\n",
    "enc_outputs = src_emb(word_index)\n",
    "print(enc_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03bb06e-edbd-4330-8860-c7bd33221ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:24:00.647.535 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.          1.          0.          1.        ]\n",
      "  [ 0.84147096  0.5403023   0.00999983  0.99995   ]\n",
      "  [ 0.9092974  -0.4161468   0.01999866  0.9998    ]\n",
      "  [ 0.14112009 -0.98999447  0.0299955   0.99955004]\n",
      "  [-0.7568025  -0.6536437   0.03998933  0.9992001 ]\n",
      "  [-0.9589243   0.28366202  0.04997917  0.9987502 ]\n",
      "  [-0.27941567  0.96017027  0.059964    0.99820054]\n",
      "  [ 0.6569864   0.7539024   0.06994284  0.997551  ]\n",
      "  [ 0.98935825 -0.14549987  0.07991469  0.99680173]\n",
      "  [ 0.4121185  -0.9111306   0.08987855  0.9959527 ]]]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "from mindspore import nn, ops, Tensor\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore import numpy as mnp\n",
    "\n",
    "class PositionalEncoding(nn.Cell):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout_p=0.1, max_len=100):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(1 - dropout_p)\n",
    "\n",
    "        self.pe = ops.Zeros()((max_len, d_model), mstype.float32)\n",
    "\n",
    "        pos = mnp.arange(0, max_len, dtype=mstype.float32).view((-1, 1))\n",
    "        angle = ops.pow(10000.0, mnp.arange(0, d_model, 2, dtype=mstype.float32)/d_model)\n",
    "\n",
    "        self.pe[:, 0::2] = ops.sin(pos/angle)\n",
    "        self.pe[:, 1::2] = ops.cos(pos/angle)\n",
    "\n",
    "    def construct(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        pe = self.pe.expand_dims(0)\n",
    "        pe = ops.broadcast_to(pe, (batch_size, -1, -1))\n",
    "\n",
    "        x = x + pe[:, :x.shape[1], :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "x = ops.Zeros()((1, 10, 4), mstype.float32)\n",
    "pe = PositionalEncoding(4)\t\n",
    "print(pe(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d5b0673-1379-45a8-822c-bc507010a7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:24:14.193.144 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 8, 32, 64) (128, 8, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "class ScaledDotProductAttention(nn.Cell):\n",
    "    def __init__(self, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(1-dropout_p)\n",
    "        self.sqrt = ops.Sqrt()\n",
    "\n",
    "\n",
    "    def construct(self, query, key, value, attn_mask=None):\n",
    "        \"\"\"scaled dot product attention\"\"\"\n",
    "        embed_size = query.shape[-1]\n",
    "        scaling_factor = self.sqrt(Tensor(embed_size, mstype.float16))\n",
    "\n",
    "        attn = ops.matmul(query, key.swapaxes(-2, -1) / scaling_factor)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn = attn.masked_fill(attn_mask, -1e9)\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = ops.matmul(attn, value)\n",
    "\n",
    "        return (output, attn)\n",
    "\n",
    "\n",
    "attention = ScaledDotProductAttention()\n",
    "q_s = k_s = v_s = ops.ones((128, 8, 32, 64), mindspore.float32)\n",
    "attn_mask = ops.ones((128, 8, 32, 32), mindspore.float32)\n",
    "attn_mask = mindspore.ops.gt(attn_mask, attn_mask)\n",
    "output, attn = attention(q_s, k_s, v_s, attn_mask)\n",
    "print(output.shape, attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7048517-0bf0-4637-aac8-9b6818fa99f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:24:26.391.854 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.shape:(128, 32, 512)\n",
      "attn_mask.shape:(128, 8, 32, 32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.W_Q = nn.Dense(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Dense(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Dense(d_model, d_k * n_heads)\n",
    "        self.W_O = nn.Dense(n_heads * d_k, d_model)\n",
    "        self.attention = ScaledDotProductAttention(dropout_p=dropout_p)\n",
    "\n",
    "    def construct(self, query, key, value, attn_mask):\n",
    "        \"\"\"\n",
    "        query: [batch_size, len_q, d_model]\n",
    "        key: [batch_size, len_k, d_model]\n",
    "        value: [batch_size, len_k, d_model]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = query.shape[0]\n",
    "\n",
    "        q_s = self.W_Q(query).view(batch_size, -1, self.n_heads, self.d_k)\n",
    "        k_s = self.W_K(key).view(batch_size, -1, self.n_heads, self.d_k)\n",
    "        v_s = self.W_V(value).view(batch_size, -1, self.n_heads, self.d_k)\n",
    "\n",
    "        q_s = q_s.transpose((0, 2, 1, 3))\n",
    "        k_s = k_s.transpose((0, 2, 1, 3))\n",
    "        v_s = v_s.transpose((0, 2, 1, 3))\n",
    "\n",
    "        attn_mask = attn_mask.expand_dims(1)\n",
    "        attn_mask = ops.tile(attn_mask, (1, self.n_heads, 1, 1))\n",
    "\n",
    "        context, attn = self.attention(q_s, k_s, v_s, attn_mask)\n",
    "\n",
    "        context = context.transpose((0, 2, 1, 3)).view((batch_size, -1, self.n_heads * self.d_k))\n",
    "\n",
    "        output = self.W_O(context)\n",
    "\n",
    "        return output, attn\n",
    "\n",
    "enc_input = ops.ones((128, 32, 512), mindspore.float32)\n",
    "attn_mask = ops.ones((128, 32, 32), mindspore.float32)\n",
    "attn_mask = mindspore.ops.gt(attn_mask, attn_mask)\n",
    "\n",
    "mha = MultiHeadAttention(512, 64, 8)\n",
    "output, attn = mha(enc_input, enc_input, enc_input, attn_mask)\n",
    "print(\"output.shape:{}\\nattn_mask.shape:{}\\n\".format(output.shape, attn.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b97ef4e-2dc9-4f4d-8f48-7bbbf11a9ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[False False  True  True]\n",
      "  [False False  True  True]\n",
      "  [False False  True  True]\n",
      "  [False False  True  True]]]\n"
     ]
    }
   ],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k, pad_idx):\n",
    "    \"\"\"注意力掩码：识别序列中的<pad>占位符\n",
    "\n",
    "    Args:\n",
    "        seq_q (Tensor): query序列，shape = [batch size, query len]\n",
    "        seq_k (Tensor): key序列，shape = [batch size, key len]\n",
    "        pad_idx (Tensor): key序列<pad>占位符对应的数字索引\n",
    "    \"\"\"\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "\n",
    "    pad_attn_mask = ops.equal(seq_k, pad_idx)\n",
    "\n",
    "    pad_attn_mask = pad_attn_mask.expand_dims(1)\n",
    "    pad_attn_mask = ops.broadcast_to(pad_attn_mask, (batch_size, len_q, len_k))\n",
    "\n",
    "    return pad_attn_mask\n",
    "\n",
    "q = k = Tensor([[1, 1, 0, 0]], mstype.float32)\n",
    "pad_idx = 0\n",
    "mask = get_attn_pad_mask(q, k, pad_idx)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57bcb800-da6d-404f-ae30-eda157cf423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:24:42.516.726 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 512)\n"
     ]
    }
   ],
   "source": [
    "class PoswiseFeedForward(nn.Cell):\n",
    "    def __init__(self, d_ff, d_model, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Dense(d_model, d_ff)\n",
    "        self.linear2 = nn.Dense(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(1-dropout_p)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"前馈神经网络\n",
    "        x: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        output = self.linear2(x)\n",
    "        return output\n",
    "\n",
    "x = ops.ones((128, 32, 512), mstype.float32)\n",
    "ffn = PoswiseFeedForward(2048, 512)\n",
    "print(ffn(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cca98d11-398b-419a-9e8b-0588bb5ba47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Cell):\n",
    "    def __init__(self, d_model, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm((d_model, ), epsilon=1e-5)\n",
    "        self.dropout = nn.Dropout(1-dropout_p)\n",
    "    \n",
    "    def construct(self, x, residual):\n",
    "        return self.layer_norm(self.dropout(x) + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c4ffe0e-b08d-4427-9ef9-d9ababd46394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:24:57.800.889 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:24:57.819.933 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:24:57.824.734 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:24:57.828.367 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 512) (128, 8, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        d_k = d_model // n_heads\n",
    "        if d_k * n_heads != d_model:\n",
    "            raise ValueError(f\"The `d_model` {d_model} can not be divisible by `num_heads` {n_heads}.\")\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, d_k, n_heads, dropout_p)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model, dropout_p)\n",
    "        self.add_norm1 = AddNorm(d_model, dropout_p)\n",
    "        self.add_norm2 = AddNorm(d_model, dropout_p)\n",
    "        \n",
    "    def construct(self, enc_inputs, enc_self_attn_mask):\n",
    "        \"\"\"\n",
    "        enc_inputs: [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        \"\"\"\n",
    "        residual = enc_inputs\n",
    "\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
    "\n",
    "        enc_outputs = self.add_norm1(enc_outputs, residual)\n",
    "        residual = enc_outputs\n",
    "\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)\n",
    "\n",
    "        enc_outputs = self.add_norm2(enc_outputs, residual)\n",
    "\n",
    "        return enc_outputs, attn\n",
    "\n",
    "x = ops.ones((128, 32, 512), mstype.float32)\n",
    "mask = Tensor([False]).broadcast_to((128, 32, 32))\n",
    "encoder_layer = EncoderLayer(512, 8, 2018)\n",
    "output, attn = encoder_layer(x, mask)\n",
    "print(output.shape, attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62c7c88c-86e8-49f3-a559-c702215e810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:08.175.195 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:08.214.859 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:08.242.789 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:08.247.431 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:08.251.507 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_outputs.shape:(128, 32, 512)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Cell):\n",
    "    def __init__(self, src_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model, dropout_p)\n",
    "        self.layers = nn.CellList([EncoderLayer(d_model, n_heads, d_ff, dropout_p)] * n_layers)\n",
    "        self.scaling_factor = ops.Sqrt()(Tensor(d_model, mstype.float32))\n",
    "\n",
    "    def construct(self, enc_inputs, src_pad_idx):\n",
    "        \"\"\"enc_inputs : [batch_size, src_len]\n",
    "        \"\"\"\n",
    "        enc_outputs = self.src_emb(enc_inputs.astype(mstype.int32))\n",
    "        enc_outputs = self.pos_emb(enc_outputs * self.scaling_factor)\n",
    "\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs, src_pad_idx)\n",
    "\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns\n",
    "\n",
    "encoder = Encoder(len(de_vocab), 512, 8, 2048, 6)\n",
    "\n",
    "for src_idx, src_len, trg_idx in train_iterator():\n",
    "    enc_outputs, enc_self_attns = encoder(src_idx, de_vocab.pad_idx)\n",
    "    print(\"enc_outputs.shape:{}\\n\".format(enc_outputs.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614bca77-0b95-4f80-ab38-45b6339c96bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 1. 1.]\n",
      "  [0. 0. 1. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "def get_attn_subsequent_mask(seq_q, seq_k):\n",
    "    \"\"\"生成时间掩码，使decoder在第t时刻只能看到序列的前t-1个元素\n",
    "    \n",
    "    Args:\n",
    "        seq_q (Tensor): query序列，shape = [batch size, len_q]\n",
    "        seq_k (Tensor): key序列，shape = [batch size, len_k]\n",
    "    \"\"\"\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "    ones = ops.ones((batch_size, len_q, len_k), mindspore.float32)\n",
    "    subsequent_mask = mnp.triu(ones, k=1)\n",
    "    return subsequent_mask\n",
    "\n",
    "q = k = ops.ones((1, 4), mstype.float32)\n",
    "mask = get_attn_subsequent_mask(q, k)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4714c4ed-7ed6-41bf-aa5b-37e7e42e1d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:24.859.005 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:24.883.675 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:24.900.152 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:24.905.351 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:24.908.956 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:24.912.877 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 512) (128, 8, 32, 32) (128, 8, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        d_k = d_model // n_heads\n",
    "        if d_k * n_heads != d_model:\n",
    "            raise ValueError(f\"The `d_model` {d_model} can not be divisible by `num_heads` {n_heads}.\")\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, d_k, n_heads, dropout_p)\n",
    "        self.dec_enc_attn = MultiHeadAttention(d_model, d_k, n_heads, dropout_p)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model, dropout_p)\n",
    "        self.add_norm1 = AddNorm(d_model, dropout_p)\n",
    "        self.add_norm2 = AddNorm(d_model, dropout_p)\n",
    "        self.add_norm3 = AddNorm(d_model, dropout_p)\n",
    "        \n",
    "    def construct(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        \"\"\"\n",
    "        dec_inputs: [batch_size, trg_len, d_model]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        dec_self_attn_mask: [batch_size, trg_len, trg_len]\n",
    "        dec_enc_attn_mask: [batch_size, trg_len, src_len]\n",
    "        \"\"\"\n",
    "        residual = dec_inputs\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        dec_outputs = self.add_norm1(dec_outputs, residual)\n",
    "        residual = dec_outputs    \n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_outputs = self.add_norm2(dec_outputs, residual)\n",
    "        residual = dec_outputs\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)\n",
    "        dec_outputs = self.add_norm3(dec_outputs, residual)\n",
    "\n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn\n",
    "\n",
    "x = y = ops.ones((128, 32, 512), mstype.float32)\n",
    "mask1 = mask2 = Tensor([False]).broadcast_to((128, 32, 32))\n",
    "decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "output, attn1, attn2 = decoder_layer(x, y, mask1, mask2)\n",
    "print(output.shape, attn1.shape, attn2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad8568f3-1420-4082-bb92-36489ad49818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Cell):\n",
    "    def __init__(self, trg_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.trg_emb = nn.Embedding(trg_vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model, dropout_p)\n",
    "        self.layers = nn.CellList([DecoderLayer(d_model, n_heads, d_ff) for _ in range(n_layers)])\n",
    "        self.projection = nn.Dense(d_model, trg_vocab_size)\n",
    "        self.scaling_factor = ops.Sqrt()(Tensor(d_model, mstype.float32))      \n",
    "        \n",
    "    def construct(self, dec_inputs, enc_inputs, enc_outputs, src_pad_idx, trg_pad_idx):\n",
    "        \"\"\"\n",
    "        dec_inputs: [batch_size, trg_len]\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        \"\"\"\n",
    "        dec_outputs = self.trg_emb(dec_inputs.astype(mstype.int32))\n",
    "        dec_outputs = self.pos_emb(dec_outputs * self.scaling_factor)\n",
    "\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, trg_pad_idx)\n",
    "        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs, dec_inputs)\n",
    "        dec_self_attn_mask = ops.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)\n",
    "\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, src_pad_idx)\n",
    "\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        dec_outputs = self.projection(dec_outputs)\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b2762ce-d746-45ae-b6b9-86738d32df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Cell):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.encoder.to_float(mindspore.float16)\n",
    "        self.decoder.to_float(mindspore.float16)\n",
    "        \n",
    "    def construct(self, enc_inputs, dec_inputs, src_pad_idx, trg_pad_idx):\n",
    "        \"\"\"\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        dec_inputs: [batch_size, trg_len]\n",
    "        \"\"\"\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs, src_pad_idx)\n",
    "\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs, src_pad_idx, trg_pad_idx)\n",
    "\n",
    "        dec_logits = dec_outputs.view((-1, dec_outputs.shape[-1]))\n",
    "\n",
    "        return dec_logits, enc_self_attns, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77bb4ebb-eac5-4f82-8394-e94b51c15124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.500.078 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.530.519 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.546.907 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.551.576 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.555.294 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.580.102 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.608.509 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.630.124 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.658.672 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.663.268 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.667.317 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.671.127 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.691.787 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.713.278 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.732.960 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.737.900 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.742.101 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.746.141 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.766.825 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.787.045 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.804.701 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.812.545 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.817.139 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.821.311 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.847.351 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.873.145 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.890.087 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.895.000 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.898.753 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.903.162 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.922.194 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.966.756 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.983.943 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.988.717 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.992.781 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:53.996.596 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:54.185.46 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:54.376.48 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:54.672.62 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:54.721.84 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:54.759.92 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:25:54.804.91 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(de_vocab)\n",
    "trg_vocab_size = len(en_vocab)\n",
    "src_pad_idx = de_vocab.pad_idx\n",
    "trg_pad_idx = en_vocab.pad_idx\n",
    "\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "n_layers = 6\n",
    "n_heads = 8\n",
    "\n",
    "encoder = Encoder(src_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.1)\n",
    "decoder = Decoder(trg_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.1)\n",
    "model = Transformer(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1569c8ce-fde1-4a3f-a231-4ee4740adc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea40bfcd-79b5-4e26-b098-c6d08b5f64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(enc_inputs, dec_inputs):\n",
    "    \"\"\"前向网络\n",
    "    enc_inputs: [batch_size, src_len]\n",
    "    dec_inputs: [batch_size, trg_len]\n",
    "    \"\"\"\n",
    "    logits, _, _, _ = model(enc_inputs, dec_inputs[:, :-1], src_pad_idx, trg_pad_idx)\n",
    "\n",
    "    targets = dec_inputs[:, 1:].view(-1)\n",
    "    loss = loss_fn(logits, targets)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27f922f6-9ea8-4257-80a1-0b69062e4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = ops.value_and_grad(forward, None, optimizer.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efecf8f4-574e-4bd9-8d94-3dcde21d7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(iterator, epoch=0):\n",
    "    model.set_train(True)\n",
    "    num_batches = len(iterator)\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "\n",
    "    with tqdm(total=num_batches, unit='step', desc='Train   ') as t:\n",
    "        for src, src_len, trg in iterator():\n",
    "            loss, grads = grad_fn(src, trg)\n",
    "            optimizer(grads)\n",
    "\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_steps += 1\n",
    "            curr_loss = total_loss / total_steps\n",
    "            t.set_postfix({'loss': f'{curr_loss:.2f}', 'epoch': f'{epoch:03}'})\n",
    "            t.update(1)\n",
    "\n",
    "    return total_loss / total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1000f405-8865-4b41-bd8b-1431efd24451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(iterator):\n",
    "    model.set_train(False)\n",
    "    num_batches = len(iterator)\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "\n",
    "    with tqdm(total=num_batches, unit='step', desc='Evaluate') as t:\n",
    "        for src, _, trg in iterator():\n",
    "            loss = forward(src, trg)\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_steps += 1\n",
    "            curr_loss = total_loss / total_steps\n",
    "            t.set_postfix({'loss': f'{curr_loss:.2f}'})\n",
    "            t.update(1)\n",
    "\n",
    "    return total_loss / total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b070c32d-2bb0-4435-a778-db83c0f1b8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train   :   0%|          | 0/226 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train   : 100%|██████████| 226/226 [01:55<00:00,  1.96step/s, loss=4.49, epoch=000]\n",
      "Evaluate:  88%|████████▊ | 7/8 [00:01<00:00,  6.53step/s, loss=3.41]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 8/8 [00:03<00:00,  2.02step/s, loss=3.44]\n",
      "Train   : 100%|██████████| 226/226 [01:04<00:00,  3.51step/s, loss=3.05, epoch=001]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  6.68step/s, loss=2.56]\n",
      "Train   : 100%|██████████| 226/226 [01:03<00:00,  3.55step/s, loss=2.40, epoch=002]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  6.88step/s, loss=2.15]\n",
      "Train   : 100%|██████████| 226/226 [01:03<00:00,  3.53step/s, loss=2.02, epoch=003]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  6.96step/s, loss=1.92]\n",
      "Train   : 100%|██████████| 226/226 [01:02<00:00,  3.60step/s, loss=1.76, epoch=004]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.18step/s, loss=1.81]\n",
      "Train   : 100%|██████████| 226/226 [01:03<00:00,  3.58step/s, loss=1.55, epoch=005]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.52step/s, loss=1.74]\n",
      "Train   : 100%|██████████| 226/226 [01:02<00:00,  3.60step/s, loss=1.39, epoch=006]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.13step/s, loss=1.68]\n",
      "Train   : 100%|██████████| 226/226 [01:02<00:00,  3.61step/s, loss=1.25, epoch=007]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.35step/s, loss=1.63]\n",
      "Train   : 100%|██████████| 226/226 [01:02<00:00,  3.62step/s, loss=1.13, epoch=008]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.55step/s, loss=1.61]\n",
      "Train   : 100%|██████████| 226/226 [01:02<00:00,  3.59step/s, loss=1.02, epoch=009]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.25step/s, loss=1.62]\n"
     ]
    }
   ],
   "source": [
    "from mindspore import save_checkpoint\n",
    "\n",
    "num_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "ckpt_file_name = './transformer.ckpt'\n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    train_loss = train(train_iterator, i)\n",
    "    valid_loss = evaluate(valid_iterator)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        save_checkpoint(model, ckpt_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efa7a3d3-12be-4a61-a329-f074705c7d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.748.235 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.776.056 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.796.775 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.801.417 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.805.249 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.825.188 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.846.074 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.875.156 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.892.006 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.896.658 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.900.740 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.904.628 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.924.212 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.962.363 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.982.627 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.988.029 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.991.711 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:41.995.439 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.172.99 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.384.16 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.681.38 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.729.16 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.769.34 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.810.07 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.104.236 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.124.007 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.154.741 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.159.391 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.163.487 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.168.167 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.191.348 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.215.303 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.236.207 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.240.587 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.245.080 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.249.058 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.271.646 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.291.434 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.310.323 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.315.264 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.319.576 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(117430:281473689231536,MainProcess):2025-04-19-18:38:42.323.671 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "encoder = Encoder(src_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.1)\n",
    "decoder = Decoder(trg_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.1)\n",
    "new_model = Transformer(encoder, decoder)\n",
    "\n",
    "param_dict = load_checkpoint(ckpt_file_name)\n",
    "load_param_into_net(new_model, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6db1cc8-98ec-490c-85a4-6569433de1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(sentence, max_len=32):\n",
    "    \"\"\"模型推理：输入一个德语句子，输出翻译后的英文句子\n",
    "    enc_inputs: [batch_size(1), src_len]\n",
    "    \"\"\"\n",
    "    new_model.set_train(False)\n",
    "\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [tok.lower() for tok in re.findall(r'\\w+|[^\\w\\s]', sentence.rstrip())]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    if len(tokens) > max_len - 2:\n",
    "        src_len = max_len\n",
    "        tokens = ['<bos>'] + tokens[:max_len - 2] + ['<eos>']\n",
    "    else:\n",
    "        src_len = len(tokens) + 2\n",
    "        tokens = ['<bos>'] + tokens + ['<eos>'] + ['<pad>'] * (max_len - src_len)\n",
    "\n",
    "    indexes = de_vocab.encode(tokens)\n",
    "    enc_inputs = Tensor(indexes, mstype.float32).expand_dims(0)\n",
    "\n",
    "    enc_outputs, _ = new_model.encoder(enc_inputs, src_pad_idx)\n",
    "\n",
    "    dec_inputs = Tensor([[en_vocab.bos_idx]], mstype.float32)\n",
    "\n",
    "    max_len = enc_inputs.shape[1]\n",
    "    for _ in range(max_len):\n",
    "        dec_outputs, _, _ = new_model.decoder(dec_inputs, enc_inputs, enc_outputs, src_pad_idx, trg_pad_idx)\n",
    "        dec_logits = dec_outputs.view((-1, dec_outputs.shape[-1]))\n",
    "\n",
    "        dec_logits = dec_logits[-1, :]\n",
    "        pred = dec_logits.argmax(axis=0).expand_dims(0).expand_dims(0)\n",
    "        pred = pred.astype(mstype.float32)\n",
    "\n",
    "        dec_inputs = ops.concat((dec_inputs, pred), axis=1)\n",
    "\n",
    "        if int(pred.asnumpy()[0]) == en_vocab.eos_idx:\n",
    "            break\n",
    "\n",
    "    trg_indexes = [int(i) for i in dec_inputs.view(-1).asnumpy()]\n",
    "    eos_idx = trg_indexes.index(en_vocab.eos_idx) if en_vocab.eos_idx in trg_indexes else -1\n",
    "    trg_tokens = en_vocab.decode(trg_indexes[1:eos_idx])\n",
    "\n",
    "    return trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3317f1c1-cedf-4d65-838a-6b81e0a0b556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['ein', 'mann', 'mit', 'einem', 'orangefarbenen', 'hut', ',', 'der', 'etwas', 'anstarrt', '.']\n",
      "trg = ['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.']\n",
      "predicted trg = ['a', 'man', 'in', 'an', 'orange', 'hat', 'is', '<unk>', 'something', 'something', '.']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 0\n",
    "\n",
    "src = test_dataset[example_idx][0]\n",
    "trg = test_dataset[example_idx][1]\n",
    "pred_trg = inference(src)\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')\n",
    "print(f\"predicted trg = {pred_trg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a2d98cd-88ba-414d-8461-1a51c1f82225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 39.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0xffffa3108700>\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def calculate_bleu(dataset, max_len=50):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for data in dataset[:10]:\n",
    "        \n",
    "        src = data[0]\n",
    "        trg = data[1]\n",
    "\n",
    "        pred_trg = inference(src, max_len)\n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return corpus_bleu(trgs, pred_trgs)\n",
    "\n",
    "bleu_score = calculate_bleu(test_dataset)\n",
    "\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
